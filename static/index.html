<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <title>WebRTC Interview (Python)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <style>
    body { font-family: system-ui, Arial, sans-serif; margin: 24px; }
    .row { display:flex; gap:12px; align-items:center; flex-wrap:wrap; }
    button { padding:10px 14px; font-size:14px; cursor:pointer; }
    #log { white-space:pre-wrap; border:1px solid #ddd; padding:12px; margin-top:12px; height:200px; overflow:auto; }
    #textout { border:1px solid #ddd; min-height:80px; padding:10px; margin-top:12px; }
  </style>
</head>
<body>
  <h1>WebRTC Interview (English-only)</h1>
  <div class="row">
    <button id="connect">Connect</button>
    <button id="startInterview" disabled>Start Interview</button>
    <button id="hangup" disabled>Hang Up</button>
  </div>
  <audio id="remoteAudio" autoplay></audio>

  <h3>Transcript</h3>
  <div id="textout"></div>

  <h3>Log</h3>
  <div id="log"></div>

<script>
const $ = (id) => document.getElementById(id);
const log = (msg) => { $("log").textContent += msg + "\n"; };
const appendText = (t) => { $("textout").textContent += t; };

let pc;
let dc;
let micStream;

async function getEphemeral() {
  const r = await fetch("/session", { method: "POST" });
  if (!r.ok) {
    const txt = await r.text();
    throw new Error("Failed to create session: " + txt);
  }
  return await r.json(); // includes client_secret
}

async function connect() {
  $("connect").disabled = true;
  $("startInterview").disabled = true;
  $("hangup").disabled = false;

  // 1) Get mic
  micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
  log("Mic acquired.");

  // 2) New RTCPeerConnection
  pc = new RTCPeerConnection();
  micStream.getTracks().forEach(t => pc.addTrack(t, micStream));

  // Remote audio sink
  const remoteAudio = $("remoteAudio");
  pc.ontrack = (e) => {
    // First audio track will be model's TTS stream
    if (remoteAudio.srcObject !== e.streams[0]) {
      remoteAudio.srcObject = e.streams[0];
    }
  };

  // Data channel for text events (optional but handy)
  dc = pc.createDataChannel("oai-events");
  dc.onopen = () => log("DataChannel open.");
  dc.onmessage = (ev) => {
    try {
      const msg = JSON.parse(ev.data);
      // Stream partial/done text
      if (msg.type === "response.output_text.delta") {
        appendText(msg.delta);
      } else if (msg.type === "response.output_text.done") {
        appendText("\n");
      } else if (msg.type === "error") {
        log("[Model error] " + JSON.stringify(msg));
      }
    } catch {
      // non-JSON messages (ignore)
    }
  };

  // 3) Create local offer
  const offer = await pc.createOffer({
    offerToReceiveAudio: true,
    offerToReceiveVideo: false
  });
  await pc.setLocalDescription(offer);

  // 4) Fetch ephemeral session and exchange SDP with OpenAI
  const session = await getEphemeral();
  const EPHEMERAL_KEY = session.client_secret && session.client_secret.value;
  if (!EPHEMERAL_KEY) throw new Error("No client_secret in /session response.");

  const url = "https://api.openai.com/v1/realtime?" + new URLSearchParams({
    model: "gpt-4o-realtime-preview"
  });

  const resp = await fetch(url, {
    method: "POST",
    body: offer.sdp,
    headers: {
      "Authorization": "Bearer " + EPHEMERAL_KEY,
      "Content-Type": "application/sdp",
      "OpenAI-Beta": "realtime=v1"
    }
  });

  if (!resp.ok) {
    $("connect").disabled = false;
    $("hangup").disabled = true;
    throw new Error("SDP exchange failed: " + await resp.text());
  }

  const answerSDP = await resp.text();
  await pc.setRemoteDescription({ type: "answer", sdp: answerSDP });
  log("Connected to OpenAI Realtime.");

  $("startInterview").disabled = false;
}

function sendRealtimeEvent(obj) {
  // When the RTCPeerConnection is up, OpenAI exposes a data channel named "oai-events"
  // On some builds the model creates the channel; on others, we do and we send/receive JSON there.
  if (dc && dc.readyState === "open") {
    dc.send(JSON.stringify(obj));
  } else {
    log("DataChannel not open; cannot send.");
  }
}

function startInterview() {
  // Ask for a concise, English-only first question + force audio+text
  sendRealtimeEvent({
    type: "response.create",
    response: {
      instructions: "Answer in English only.",
      modalities: ["audio", "text"],
      conversation: {
        messages: [
          { role: "system", content: "You are an interviewer for PCB designers. Keep questions concise." },
          { role: "user", content: "Start with a short question about EDA tool experience (Ki Cad or Altium)." }
        ]
      }
    }
  });
  log("Interview prompt sent.");
}

async function hangup() {
  $("hangup").disabled = true;
  $("startInterview").disabled = true;
  $("connect").disabled = false;

  try { micStream && micStream.getTracks().forEach(t => t.stop()); } catch {}
  try { dc && dc.close(); } catch {}
  try { pc && pc.close(); } catch {}
  log("Disconnected.");
}

$("connect").onclick = () => connect().catch(e => { log(e.message); $("connect").disabled = false; });
$("startInterview").onclick = startInterview;
$("hangup").onclick = () => hangup();
</script>
</body>
</html>
